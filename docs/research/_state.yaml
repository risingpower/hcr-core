# Research State
# Machine-readable current state for session continuity
#
# Update this at session end and read at session start.

version: "1.0"
last_updated: "2026-02-20"
last_session: "2026-02-20"

# Current focus
current:
  phase: "publication"  # discovery | research | implementation | validation | publication
  focus: "Publication draft complete (docs/research/paper.md). Ready for review. Next: alternative retrieval research."
  blockers:
    - "Python _lzma module missing — pyenv Python 3.12.3 built without xz. Fix: brew install xz && pyenv install --force 3.12.3. Doesn't block publication work."

# Outcome summary
outcome:
  verdict: "HYPOTHESIS INVALIDATED"
  detail: |
    HCR embedding-based tree routing fails catastrophically at medium scale (21,897 chunks).
    nDCG dropped from 0.580 (small, 315 chunks) to 0.094 (medium, 21,897 chunks).
    Flat+CE baseline: 0.749. Gap: 0.655. Kill criterion triggered at Phase B step 3.
    Root cause: per-level routing error (ε) compounds as (1-ε)^d. At depth=5, even moderate
    ε per level means near-random leaf selection. Confirmed H1c mechanism — ε is the
    exponential lever, and current embedding-based routing cannot achieve sufficient ε at scale.

# Hypothesis resolution
hypotheses:
  - id: "H1a"
    statement: "Hierarchical coarse-to-fine achieves equivalent or better accuracy than flat similarity while using fewer tokens"
    status: "INVALIDATED"
    evidence: "nDCG 0.094 vs 0.749 at 21K chunks"
  - id: "H1b"
    statement: "Coarse elimination + fine similarity outperforms either pure approach alone"
    status: "INVALIDATED"
    evidence: "Coarse elimination destroys recall at scale"
  - id: "H1c"
    statement: "Per-level scoring quality is the primary determinant of retrieval quality — error compounds at (1-ε)^d"
    status: "CONFIRMED"
    evidence: "ε compounds at depth=5, driving nDCG from 0.580→0.094. Confirmed as mechanism of failure."

# Novel contributions (for publication)
novel_contributions:
  - name: "Per-level routing epsilon (ε)"
    description: "Metric measuring routing error at each tree level. Never measured in any prior system. Shows how error compounds exponentially with depth."
  - name: "Systematic negative result"
    description: "12 configurations tested across 2 scales, 2 embedding models, 4 routing strategies. Controlled, reproducible invalidation of embedding-based tree routing."
  - name: "Empirical patterns"
    description: "5 documented patterns: DPI summary blindness, CE routing damage, beam width as diagnostic, embedding saturation, BM25 routing sparsity."

# Key results at two scales
results_summary:
  small_corpus:
    chunks: 315
    best_hcr: "v11 (beam=8, mpnet, cosine-only): nDCG=0.580"
    flat_ce: "nDCG=0.835"
    gap: 0.255
  medium_corpus:
    chunks: 21897
    hcr: "nDCG=0.094"
    flat_ce: "nDCG=0.749"
    gap: 0.655
    tree_stats: "25,716 nodes, 3,819 internal, depth=5, 8 root branches, SD=0.445"

# Research briefs (Phase 0) — all complete
briefs:
  - {id: "RB-001", title: "Prior art survey", completed: "2026-02-13"}
  - {id: "RB-002", title: "Elimination vs similarity", completed: "2026-02-13"}
  - {id: "RB-003", title: "Scoring mechanics", completed: "2026-02-13"}
  - {id: "RB-004", title: "Tree construction", completed: "2026-02-13"}
  - {id: "RB-005", title: "Failure modes", completed: "2026-02-13"}
  - {id: "RB-006", title: "Benchmark design", completed: "2026-02-13"}

# Experimental history (12 configs)
experiment_history:
  - {id: "v1", note: "OBSOLETE — flat tree builder bug", ndcg: 0.345}
  - {id: "v2", note: "First proper tree, CE all levels", ndcg: 0.318}
  - {id: "v3", note: "Cosine-only routing", ndcg: 0.287}
  - {id: "v4", note: "Beam=5 cosine-only", ndcg: 0.420}
  - {id: "v5", note: "Beam=8 ceiling (MiniLM)", ndcg: 0.509}
  - {id: "v6", note: "Enriched embed text", ndcg: 0.493}
  - {id: "v7", note: "Contrastive prompts (wash)", ndcg: 0.484}
  - {id: "v8", note: "Content snippets (wash)", ndcg: 0.485}
  - {id: "v9", note: "mpnet no rebuild (WORSE)", ndcg: 0.450}
  - {id: "v10", note: "mpnet rebuilt tree (BEST beam=5)", ndcg: 0.540}
  - {id: "v11", note: "mpnet beam=8 (BEST overall)", ndcg: 0.580}
  - {id: "v12", note: "BM25 hybrid routing (NEGATIVE)", ndcg: 0.465}

# Knowledge patterns
knowledge:
  patterns:
    - "DPI summary blindness — coarse summaries lack detail for specific queries"
    - "CE routing damage — MS-MARCO CE net negative on structured routing metadata"
    - "Beam width as diagnostic — monotonic ε improvement confirms tree structure sound"
    - "Embedding saturation — MiniLM 384-dim space saturated for summary discrimination"
    - "BM25 routing sparsity — BM25 over ~10-20 token keyword lists produces noise"

# Implementation stats
implementation:
  test_count: 126
  mypy_status: "clean"
  ruff_status: "clean"
  sessions: 10  # sessions 1-10 (Feb 13-20)

# Next actions
next_actions:
  - id: 1
    action: "Plan and write publication document"
    status: DONE
    details: "Paper written: docs/research/paper.md. All numbers cross-checked against source JSON."
  - id: 2
    action: "Review and refine paper"
    status: TODO
    details: "JC review of paper.md. Refine language, add full author info, verify LATTICE citation."
  - id: 3
    action: "Research alternative retrieval approaches"
    status: TODO
    details: "Evaluate alternatives for the use case (minimum viable context for LLM systems)."

# Session notes
notes: |
  SESSION 2026-02-20 (session 10):
  Publication draft complete. Wrote docs/research/paper.md (~12 pages).
  All numbers cross-checked against source JSON files. 4 discrepancies found and fixed.
  Updated _state.yaml and hypotheses.md.

  SESSION 2026-02-19 (session 9):
  Cleaned up _state.yaml. Planning publication work.

  SESSION 2026-02-19 (session 8b — same day as 8, different session):
  Medium fail-fast KILLED HCR. nDCG=0.094 vs Flat+CE=0.749 at 21K chunks.
  Hypothesis invalidated. All three sub-hypotheses resolved.

  SESSION 2026-02-18 (session 8):
  Medium corpus prepared (21,897 chunks, 150 queries). Sanity check passed.

  SESSION 2026-02-17 (session 7):
  Phase B infrastructure complete. --scale flag, Wikipedia loader, fail-fast mode.

  SESSION 2026-02-16 (sessions 3-6):
  Phase A complete. 12 configs tested. Best: v11 (nDCG=0.580). BM25 hybrid negative.
  Proceeded to Phase B scale-up.

  SESSION 2026-02-15 (session 2):
  Baselines established. Flat+CE kill baseline: nDCG=0.835.

  SESSION 2026-02-13 (session 1):
  All 6 research briefs completed. Go/no-go: GO on Phase 1.
